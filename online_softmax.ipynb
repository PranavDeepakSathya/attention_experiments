{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca6d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "\n",
    "def safe_softmax(vector): \n",
    "  l = np.size(vector)\n",
    "  out = np.zeros(l)\n",
    "  maxim = float(\"-inf\")\n",
    "  denom = 0 \n",
    "  #first pass, calculate max \n",
    "  for i in range(l): \n",
    "    maxim = max(vector[i],maxim)\n",
    "  #second pass, calculate denom \n",
    "  for i in range(l): \n",
    "    denom += math.exp(vector[i] - maxim)\n",
    "  #third pass, calculate softmax \n",
    "  for i in range(l):\n",
    "    out[i] = math.exp(vector[i]-maxim)/denom\n",
    "    \n",
    "  return out \n",
    "\n",
    "def ref_softmax(vector): \n",
    "  max = np.max(vector)\n",
    "  denom = np.sum(np.exp(vector-max))\n",
    "  return np.exp(vector-max)/denom\n",
    "\n",
    "\n",
    "def safe_online_softmax(vector): \n",
    "  prev_maxim = float(\"-inf\")\n",
    "  prev_denom = 0\n",
    "  maxim = prev_maxim\n",
    "  denom = prev_denom\n",
    "  l = np.size(vector)\n",
    "  out = np.zeros(l)\n",
    "  for i in range(l): \n",
    "    maxim = max(prev_maxim, vector[i])\n",
    "    denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(vector[i]-maxim)\n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    \n",
    "  for i in range(l): \n",
    "    out[i] = math.exp(vector[i]-maxim)/denom\n",
    "  return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29562320",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.random.randn(16)\n",
    "ref_out = ref_softmax(vector)\n",
    "out = safe_softmax(vector)\n",
    "online_out = safe_online_softmax(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea9b6777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02561199, 0.02492177, 0.01480078, 0.02532539, 0.08511779,\n",
       "       0.05392862, 0.01046387, 0.00611335, 0.06218651, 0.02227012,\n",
       "       0.03050929, 0.04931391, 0.40017593, 0.15116785, 0.00879579,\n",
       "       0.02929706])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8765f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02561199, 0.02492177, 0.01480078, 0.02532539, 0.08511779,\n",
       "       0.05392862, 0.01046387, 0.00611335, 0.06218651, 0.02227012,\n",
       "       0.03050929, 0.04931391, 0.40017593, 0.15116785, 0.00879579,\n",
       "       0.02929706])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4513ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float('-inf')]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8a07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "971691f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_element_attention:\n",
    "  def __init__ (self, D, L_k):\n",
    "    self.Q_row = np.random.randn(1,D)\n",
    "    self.K_T = np.random.randn(D,L_k)\n",
    "    self.S_row = np.zeros((1,L_k))\n",
    "    self.P_row = np.zeros_like(self.S_row)\n",
    "    self.V_col = np.random.randn(L_k,1)\n",
    "\n",
    "  def zero_out(self): \n",
    "    self.S_row = np.zeros_like(self.S_row)\n",
    "    self.P_row = np.zeros_like(self.S_row)\n",
    "    \n",
    "  def naive_attention(self): \n",
    "    out = 0\n",
    "    self.zero_out() \n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    for lk in range(L_k): \n",
    "      maxim = max(maxim, self.S_row[0,lk])\n",
    "    for lk in range(L_k): \n",
    "      denom += math.exp((self.S_row[0,lk]-maxim))\n",
    "    for lk in range(L_k): \n",
    "      self.P_row[0,lk] = math.exp((self.S_row[0,lk]-maxim))/denom\n",
    "    for lk in range(L_k): \n",
    "      out += self.P_row[0,lk]*self.V_col[lk,0]\n",
    "      \n",
    "    return out \n",
    "  \n",
    "  def attention_V0(self): \n",
    "    #we dont need to materialize P_row \n",
    "    out = 0\n",
    "    self.zero_out() \n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    for lk in range(L_k): \n",
    "      maxim = max(maxim, self.S_row[0,lk])\n",
    "    for lk in range(L_k): \n",
    "      denom += math.exp((self.S_row[0,lk]-maxim))\n",
    "    for lk in range(L_k): \n",
    "     out += (math.exp((self.S_row[0,lk]-maxim))/denom)*self.V_col[lk,0];\n",
    "   \n",
    "    return out \n",
    "  \n",
    "  def attention_V1(self): \n",
    "    #online softmax \n",
    "    out = 0 \n",
    "    self.zero_out()\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    D,L_k = self.K_T.shape \n",
    "    \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "      maxim = max(prev_maxim, self.S_row[0,lk])\n",
    "      denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(self.S_row[0,lk]-maxim)\n",
    "      prev_maxim = maxim \n",
    "      prev_denom = denom \n",
    "    \n",
    "    for lk in range(L_k): \n",
    "     out += (math.exp((self.S_row[0,lk]-maxim))/denom)*self.V_col[lk,0]\n",
    "   \n",
    "    return out \n",
    "  \n",
    "  \n",
    "  def attention_V2(self): \n",
    "    #flash\n",
    "    \n",
    "    self.zero_out()\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    out = 0 \n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    prev_out = out\n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "      maxim = max(prev_maxim, self.S_row[0,lk])\n",
    "      denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(self.S_row[0,lk]-maxim)\n",
    "      out = prev_out*math.exp(prev_maxim-maxim) + (math.exp(self.S_row[0,lk]-maxim)*self.V_col[lk,0])\n",
    "\n",
    "      prev_maxim = maxim \n",
    "      prev_denom = denom \n",
    "      prev_out = out\n",
    "\n",
    "    return out/denom \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "212a2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 4\n",
    "L_k = 32\n",
    "attn = single_element_attention(D,L_k) \n",
    "\n",
    "naive_out = attn.naive_attention()\n",
    "v0_out = attn.attention_V0()\n",
    "v1_out = attn.attention_V1()\n",
    "v2_out = attn.attention_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1861980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936816099532507\n",
      "0.2936816099532507\n",
      "0.2936816099532507\n",
      "0.29368160995325077\n"
     ]
    }
   ],
   "source": [
    "print(naive_out)\n",
    "print(v0_out)\n",
    "print(v1_out)\n",
    "print(v2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89a8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
