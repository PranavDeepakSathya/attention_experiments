{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca6d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "\n",
    "\n",
    "def safe_softmax(vector): \n",
    "  l = np.size(vector)\n",
    "  out = np.zeros(l)\n",
    "  maxim = float(\"-inf\")\n",
    "  denom = 0 \n",
    "  #first pass, calculate max \n",
    "  for i in range(l): \n",
    "    maxim = max(vector[i],maxim)\n",
    "  #second pass, calculate denom \n",
    "  for i in range(l): \n",
    "    denom += math.exp(vector[i] - maxim)\n",
    "  #third pass, calculate softmax \n",
    "  for i in range(l):\n",
    "    out[i] = math.exp(vector[i]-maxim)/denom\n",
    "    \n",
    "  return out \n",
    "\n",
    "def ref_softmax(vector): \n",
    "  max = np.max(vector)\n",
    "  denom = np.sum(np.exp(vector-max))\n",
    "  return np.exp(vector-max)/denom\n",
    "\n",
    "\n",
    "def safe_online_softmax(vector): \n",
    "  prev_maxim = float(\"-inf\")\n",
    "  prev_denom = 0\n",
    "  maxim = prev_maxim\n",
    "  denom = prev_denom\n",
    "  l = np.size(vector)\n",
    "  out = np.zeros(l)\n",
    "  for i in range(l): \n",
    "    maxim = max(prev_maxim, vector[i])\n",
    "    denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(vector[i]-maxim)\n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    \n",
    "  for i in range(l): \n",
    "    out[i] = math.exp(vector[i]-maxim)/denom\n",
    "  return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29562320",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.random.randn(16)\n",
    "ref_out = ref_softmax(vector)\n",
    "out = safe_softmax(vector)\n",
    "online_out = safe_online_softmax(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9b6777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06045149, 0.01757773, 0.01369262, 0.17772275, 0.1102657 ,\n",
       "       0.07179174, 0.02581888, 0.27575512, 0.00648103, 0.02382026,\n",
       "       0.0628449 , 0.0289815 , 0.01432408, 0.01661371, 0.07084153,\n",
       "       0.02301696])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8765f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06045149, 0.01757773, 0.01369262, 0.17772275, 0.1102657 ,\n",
       "       0.07179174, 0.02581888, 0.27575512, 0.00648103, 0.02382026,\n",
       "       0.0628449 , 0.0289815 , 0.01432408, 0.01661371, 0.07084153,\n",
       "       0.02301696])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4513ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([float('-inf')]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8a07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "971691f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class single_element_attention:\n",
    "  def __init__ (self, D, L_k):\n",
    "    self.Q_row = np.random.randn(1,D)\n",
    "    self.K_T = np.random.randn(D,L_k)\n",
    "    self.S_row = np.zeros((1,L_k))\n",
    "    self.P_row = np.zeros_like(self.S_row)\n",
    "    self.V_col = np.random.randn(L_k,1)\n",
    "\n",
    "  def zero_out(self): \n",
    "    self.S_row = np.zeros_like(self.S_row)\n",
    "    self.P_row = np.zeros_like(self.S_row)\n",
    "    \n",
    "  def naive_attention(self): \n",
    "    out = 0\n",
    "    self.zero_out() \n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    for lk in range(L_k): \n",
    "      maxim = max(maxim, self.S_row[0,lk])\n",
    "    for lk in range(L_k): \n",
    "      denom += math.exp((self.S_row[0,lk]-maxim))\n",
    "    for lk in range(L_k): \n",
    "      self.P_row[0,lk] = math.exp((self.S_row[0,lk]-maxim))/denom\n",
    "    for lk in range(L_k): \n",
    "      out += self.P_row[0,lk]*self.V_col[lk,0]\n",
    "      \n",
    "    return out \n",
    "  \n",
    "  def attention_V0(self): \n",
    "    #we dont need to materialize P_row \n",
    "    out = 0\n",
    "    self.zero_out() \n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    for lk in range(L_k): \n",
    "      maxim = max(maxim, self.S_row[0,lk])\n",
    "    for lk in range(L_k): \n",
    "      denom += math.exp((self.S_row[0,lk]-maxim))\n",
    "    for lk in range(L_k): \n",
    "     out += (math.exp((self.S_row[0,lk]-maxim))/denom)*self.V_col[lk,0];\n",
    "   \n",
    "    return out \n",
    "  \n",
    "  def attention_V1(self): \n",
    "    #online softmax \n",
    "    out = 0 \n",
    "    self.zero_out()\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    D,L_k = self.K_T.shape \n",
    "    \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "      maxim = max(prev_maxim, self.S_row[0,lk])\n",
    "      denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(self.S_row[0,lk]-maxim)\n",
    "      prev_maxim = maxim \n",
    "      prev_denom = denom \n",
    "    \n",
    "    for lk in range(L_k): \n",
    "     out += (math.exp((self.S_row[0,lk]-maxim))/denom)*self.V_col[lk,0]\n",
    "   \n",
    "    return out \n",
    "  \n",
    "  \n",
    "  def attention_V2(self): \n",
    "    #flash\n",
    "    \n",
    "    self.zero_out()\n",
    "    maxim = float(\"-inf\")\n",
    "    denom = 0 \n",
    "    out = 0 \n",
    "    prev_maxim = maxim \n",
    "    prev_denom = denom \n",
    "    prev_out = out\n",
    "    \n",
    "    D,L_k = self.K_T.shape \n",
    "    \n",
    "    for lk in range(L_k):\n",
    "      for d in range(D): \n",
    "        self.S_row[0,lk] += self.Q_row[0,d]*self.K_T[d,lk]\n",
    "      maxim = max(prev_maxim, self.S_row[0,lk])\n",
    "      denom = prev_denom*math.exp(prev_maxim-maxim) + math.exp(self.S_row[0,lk]-maxim)\n",
    "      out = prev_out*math.exp(prev_maxim-maxim) + (math.exp(self.S_row[0,lk]-maxim)*self.V_col[lk,0])\n",
    "\n",
    "      prev_maxim = maxim \n",
    "      prev_denom = denom \n",
    "      prev_out = out\n",
    "\n",
    "    return out/denom \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "212a2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 4\n",
    "L_k = 32\n",
    "attn = single_element_attention(D,L_k) \n",
    "\n",
    "naive_out = attn.naive_attention()\n",
    "v0_out = attn.attention_V0()\n",
    "v1_out = attn.attention_V1()\n",
    "v2_out = attn.attention_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1861980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5062866828172767\n",
      "0.5062866828172767\n",
      "0.5062866828172765\n",
      "0.5062866828172766\n"
     ]
    }
   ],
   "source": [
    "print(naive_out)\n",
    "print(v0_out)\n",
    "print(v1_out)\n",
    "print(v2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attention: \n",
    "  def __init__ (self, B,Lq,Lkv,D):\n",
    "    self.Q = np.random.randn(B,Lq,D)\n",
    "    self.K = np.random.randn(B,Lkv,D)\n",
    "    self.V = np.random.randn(B,Lkv,D)\n",
    "    \n",
    "  def naive_attention(self): \n",
    "    B,Lq,D = self.Q.shape \n",
    "    _,Lkv,_ = self.K.shape \n",
    "    \n",
    "    S = np.matmul(self.Q, self.K.transpose(0,2,1))\n",
    "    H = np.max(S, axis=2, keepdims=True)\n",
    "    B = np.exp(S-H)\n",
    "    R = np.sum(B, axis=2, keepdims=True)\n",
    "    P = B/R \n",
    "    out = np.matmul(P,self.V)\n",
    "    return out \n",
    "    \n",
    "  def flash_attention(self,tile_Lq, tile_Lkv):\n",
    "    B,Lq,D = self.Q.shape \n",
    "    _,Lkv,_ = self.K.shape \n",
    "    O = np.zeros((B,Lq,D))\n",
    "    \n",
    "    for b in range(B): \n",
    "      for lq_start in range(0,Lq,tile_Lq): \n",
    "        #we are inside a block now \n",
    "        Q_tile = self.Q[b,lq_start:lq_start+tile_Lq,:] #load Q tile once\n",
    "        K_tile = np.zeros((tile_Lkv,D))\n",
    "        S_tile = np.zeros((tile_Lq,tile_Lkv))\n",
    "        P_unorm_tile = np.zeros((tile_Lq,tile_Lkv))\n",
    "        V_tile = np.zeros((tile_Lkv,D))\n",
    "        O_unorm_tile = np.zeros((tile_Lq,D))\n",
    "        \n",
    "        m = np.full((tile_Lq,1),-np.inf)\n",
    "        sum = np.zeros((tile_Lq,1))\n",
    "        \n",
    "        for lkv_start in range(0, Lkv, tile_Lkv): #stream over tile_Lkv chunks \n",
    "          K_tile = self.K[b,lkv_start:lkv_start + tile_Lkv,:] #load k_tile\n",
    "          V_tile = self.V[b,lkv_start:lkv_start + tile_Lkv,:] #load V_tile\n",
    "          S_tile = np.matmul(Q_tile, K_tile.transpose(1,0))\n",
    "          m_p = np.max(S_tile,axis=1,keepdims=True) \n",
    "          m_op_m_p = np.maximum(m,m_p)\n",
    "          P_unorm_tile = np.exp(S_tile-m_p)\n",
    "          sum_p = np.sum(P_unorm_tile,axis=1,keepdims=True)\n",
    "          sum_op_sum_p = (np.exp(m - m_op_m_p)*sum) + (np.exp(m_p - m_op_m_p)*sum_p)\n",
    "          O_unorm_tile_p = np.matmul(P_unorm_tile,V_tile)\n",
    "          O_unorm_tile_op_O_unorm_tile_p = (np.exp(m - m_op_m_p)*O_unorm_tile) + (np.exp(m_p - m_op_m_p)*O_unorm_tile_p)\n",
    "          \n",
    "          #state updates \n",
    "          m = m_op_m_p\n",
    "          sum = sum_op_sum_p\n",
    "          O_unorm_tile = O_unorm_tile_op_O_unorm_tile_p\n",
    "          \n",
    "        \n",
    "        O_norm_tile = O_unorm_tile/sum \n",
    "        O[b,lq_start:lq_start+tile_Lq,:] = O_norm_tile\n",
    "          \n",
    "    return O \n",
    "      \n",
    "  def flash_attention(self,tile_Lq, tile_Lkv):\n",
    "    B,Lq,D = self.Q.shape \n",
    "    _,Lkv,_ = self.K.shape \n",
    "    O = np.zeros((B,Lq,D))\n",
    "    \n",
    "    for b in range(B): \n",
    "      for lq_start in range(0,Lq,tile_Lq): \n",
    "        #we are inside a block now \n",
    "        Q_tile = self.Q[b,lq_start:lq_start+tile_Lq,:] #load Q tile once\n",
    "        K_tile = np.zeros((tile_Lkv,D))\n",
    "        S_tile = np.zeros((tile_Lq,tile_Lkv))\n",
    "        P_unorm_tile = np.zeros((tile_Lq,tile_Lkv))\n",
    "        V_tile = np.zeros((tile_Lkv,D))\n",
    "        O_unorm_tile = np.zeros((tile_Lq,D))\n",
    "        \n",
    "        m = np.full((tile_Lq,1),-np.inf)\n",
    "        sum = np.zeros((tile_Lq,1))\n",
    "        \n",
    "        for lkv_start in range(0, Lkv, tile_Lkv): #stream over tile_Lkv chunks \n",
    "          K_tile = self.K[b,lkv_start:lkv_start + tile_Lkv,:] #load k_tile\n",
    "          V_tile = self.V[b,lkv_start:lkv_start + tile_Lkv,:] #load V_tile\n",
    "          S_tile = np.matmul(Q_tile, K_tile.transpose(1,0))\n",
    "          m_p = np.max(S_tile,axis=1,keepdims=True) \n",
    "          m_op_m_p = np.maximum(m,m_p)\n",
    "          P_unorm_tile = np.exp(S_tile-m_p)\n",
    "          sum_p = np.sum(P_unorm_tile,axis=1,keepdims=True)\n",
    "          sum_op_sum_p = (np.exp(m - m_op_m_p)*sum) + (np.exp(m_p - m_op_m_p)*sum_p)\n",
    "          O_unorm_tile_p = np.matmul(P_unorm_tile,V_tile)\n",
    "          O_unorm_tile_op_O_unorm_tile_p = (np.exp(m - m_op_m_p)*O_unorm_tile) + (np.exp(m_p - m_op_m_p)*O_unorm_tile_p)\n",
    "          \n",
    "          #state updates \n",
    "          m = m_op_m_p\n",
    "          sum = sum_op_sum_p\n",
    "          O_unorm_tile = O_unorm_tile_op_O_unorm_tile_p\n",
    "          \n",
    "        \n",
    "        O_norm_tile = O_unorm_tile/sum \n",
    "        O[b,lq_start:lq_start+tile_Lq,:] = O_norm_tile\n",
    "          \n",
    "    return O \n",
    "      \n",
    "\n",
    "          \n",
    "          \n",
    "          \n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "      \n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6106050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 4\n",
    "Lq = 512\n",
    "Lkv = 1024\n",
    "D = 128 \n",
    "\n",
    "full_attn = attention(B,Lq,Lkv,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7289ee5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.882583474838611e-14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_out = full_attn.naive_attention()\n",
    "flash_out = full_attn.flash_attention(64,64)\n",
    "np.max(np.abs(naive_out - flash_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2fa1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.08474401  0.65229894 -0.03946906 ... -0.37683831  1.78059332\n",
      "    0.57918297]\n",
      "  [ 0.09741267 -0.3457442   1.41911145 ... -0.16719495  0.5994695\n",
      "   -0.42602155]\n",
      "  [ 0.23846689  0.07825328 -0.21863912 ... -0.55619378  0.10600259\n",
      "   -0.92903069]\n",
      "  ...\n",
      "  [-0.0207541  -1.96169389 -0.41279364 ... -0.57271984 -1.96023245\n",
      "   -0.37175525]\n",
      "  [-0.76412192 -0.65560993 -0.60181006 ... -0.56371247 -0.39843073\n",
      "    0.34027331]\n",
      "  [ 1.07743759  0.47668624 -0.79197136 ...  0.86937745  1.35590999\n",
      "   -1.00037621]]\n",
      "\n",
      " [[ 0.66695985  0.11751888 -2.05852617 ... -0.00346717 -1.88742228\n",
      "   -0.40554786]\n",
      "  [-0.19174458  1.56591889  0.00948206 ... -1.43062373  0.58884493\n",
      "   -0.26727037]\n",
      "  [ 1.78325227 -0.31667508 -0.37311649 ... -0.28468176 -0.24907659\n",
      "    1.11966838]\n",
      "  ...\n",
      "  [ 0.50484555 -0.08485404  0.14930034 ...  0.21414834  0.52543253\n",
      "   -0.76895862]\n",
      "  [ 0.14941039  1.28604804 -0.06261114 ... -1.37753031  0.31237288\n",
      "   -0.74885875]\n",
      "  [ 1.29731645  0.64873262  0.06791116 ... -0.84402504 -0.15333515\n",
      "   -0.49800886]]\n",
      "\n",
      " [[-0.65481475 -0.97862595 -0.31311324 ...  0.63904868 -0.1234341\n",
      "    0.72752743]\n",
      "  [ 0.59150116  0.02010157 -1.17611276 ...  0.41866293 -0.55935564\n",
      "    1.20070843]\n",
      "  [ 2.52299538  1.90897816  2.5863826  ...  0.94599059  1.25668147\n",
      "   -1.03082853]\n",
      "  ...\n",
      "  [-0.09404661 -0.01933325 -0.22083073 ... -0.47890765 -0.56920326\n",
      "   -0.08818214]\n",
      "  [ 0.59066898  0.123809    1.05306069 ...  0.51796305  0.5042456\n",
      "    0.5257801 ]\n",
      "  [ 0.64421189 -0.17454509 -0.49846167 ...  0.47281389  0.22133958\n",
      "   -0.32866532]]\n",
      "\n",
      " [[ 0.03654435 -1.85871873  0.13302547 ...  0.91987176  1.3709414\n",
      "   -0.03239774]\n",
      "  [-0.55425176  1.02504817 -0.23024974 ... -1.69712016 -1.16431579\n",
      "   -0.12430334]\n",
      "  [-1.17818809 -0.23818489 -1.68548741 ... -0.08365117  0.07364685\n",
      "    1.03713508]\n",
      "  ...\n",
      "  [ 1.35523059 -0.82782632 -0.63682763 ... -0.12473549 -1.22219585\n",
      "    1.16686205]\n",
      "  [-0.07049145 -0.80537196  0.22647588 ... -0.043067    0.24542012\n",
      "    0.33746279]\n",
      "  [-0.52262488 -0.09897    -0.58531557 ...  0.20095559 -0.87469258\n",
      "    1.14334413]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
